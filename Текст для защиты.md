Текст
Введение	4
1. Постановка задачи	5
1.1.Общая формулировка задачи классификации	5
1.2 Методы классификации, решающие деревья и случайный лес	6
1.3 Простая нейронная сеть	9
2. Практическая реализация алгоритма для решения задачи	14
Заключение	24
Список использованной литературы	25

Введение
Стремительно развивающиеся технологии позволяют человеку автоматизировать процессы, на которые раннее приходилось тратить много ценных ресурсов таких как время, нервы и прочие. Сфера машинного обучения занимается именно такими вещами, в ней мы учим алгоритмы выстроенные на основе математики находить зависимости между данными и проводить с ними различные операции. 
Одной из задач с которой успешно справляются алгоритмы машинного обучения является задача классификации. Её цель заключается в отнесении объектов к одному из заранее определённых классов на основании заданных признаков. В действительности классификация является чуть-ли не ключевой задачей анализа данных поскольку подразумевает под собой обучение алгоритма находить в данных зависимости, с которыми в последствии можно работать при решении других задач. Классификация применяется в таких важных сферах как медицина, финансы, безопасность, и так далее.
Цель курсовой работы есть изучение основ и реализация алгоритма для решения задачи классификации на основе базы данных о пациентах психоневрологических больниц.
Следующие задачи нам предстоит решить:
	Изучение базовых терминов и теории
	Постановка задачи и нахождение методов её решения
	Проведение небольшого анализа данных и их подготовка 
	Рассмотрение алгоритмов машинного обучение для задачи классификации и сравнение их результатов
В итоге имеем то, что объектом исследования является изучение алгоритма, а его предмет – реализация алгоритма и понимание принципа его работы.
Мы будем прибегать к таким методам исследования как изучение научно-технической литературы и прочих ресурсов в интернете.
1. Постановка задачи
	Общая формулировка задачи классификации 
Машинное обучение представляет из себя сферу, как я уже говорил, в которой мы обучаем алгоритмы решать различные задачи. Есть 3 основных ответвления: обучение с учителем, обучение без учителя и обучение с подкреплением. Их различия заключаются в сути алгоритмов и принципах их работы. Задача классификации относится к ветви обучения с учителем, то есть на вход алгоритма подаются данные, которые уже разделены, и алгоритму остаётся только найти в них зависимости и научится их разделять. Будем говорить, что данные уже размечены. Размеченные данные – это данные, где каждому объекту есть правильное решение. В задаче классификации правильными решениями являются метки классов, которым принадлежит рассматриваемый объект. На основе тех данных что я выбрал для курсовой работы можно сделать вывод о наличии болезни у человека. Этим и будет заниматься наш алгоритм, он будет решать задачу бинарной классификации, где предсказываемые значения у нас будут выходить нуле или 1, то есть “Да” и “Нет”. Для этого есть несколько способов о которых пойдёт речь далее.

1.2 Методы классификации, решающие деревья и случайный лес
Изучая машинное обучение можно столкнуться с различными методами классификации такими как Логистическая Регрессия, Метод Опорных векторов, Наивный Баесовский метод и т.д. Среди таких алгоритмов можно выделить алгоритм решающего дерева. Решающее дерево предсказывает значение целевой переменной с помощью применения последовательности простых решающих правил (которые называются предикатами). Этот процесс в некотором смысле согласуется с естественным для человека процессом принятия решений. Сам по себе алгоритм очень прост, но как раз поэтому их можно объединять друг с другом словно кирпичики образуя ансамбль, который в свою очередь способен на гораздо большее нежели одно дерево. В ансамбле модели решают задачу каждая самостоятельно, но при проверке их точностей получаются разногласия, из которых исходит ответ путём голосования, где большинство побеждает. Это очень хорошо повышает точность и помогает лучше справляться с задачами.
Рассмотрим пример дерева решающего задачу регрессии (предсказание числа) для более просто понимая работы алгоритма.
Здесь мы видим, что на вход алгоритму подаётся какое-то число X, которое нужно классифицировать. С каждым решением мы спускаемся от так называемого корня дерева (верхний предикат) к листу (предсказываемое значение). В каждом узле этого дерева находится предикат. Если предикат верен для текущего примера из выборки, мы переходим в правого потомка, если нет — в левого. В данном примере все предикаты — это просто взятие порога по значению какого-то признака. Алгоритм также можно визуализировать в виде разделения данных в пространстве оси X и Y.
На этом изображении предикаты являются линиями, которые отделяют куски пространства друг от друга. Суть обучения заключается в том, что исходя из зависимостей в данных наша задача создать такое дерево, которое удовлетворяет запросу задачи. Для нахождения этих самых зависимостей и разделения данных мы используем различные критерии, которые определяют, насколько вопрос информативен для решения поставленной задачи. К примеру, рассмотрим информационный критерий (entropy-based), который основан на концепции информационной энтропии, введённой учёным Клодом Шенноном. Его смысл заключается в том, что энтропия выражает степень неопределённости или хаоса в распределении классов. Чем чище распределение – тем ниже энтропия.
H(S)=−∑_(k=1)^K▒〖p_k  〖log〗_2⁡〖p_k 〗 〗 
где:
	S — текущее множество данных,
	K — количество классов, 
	p_k— доля экземпляров класса k в рассматриваемом множестве.
Энтропия достигает минимума, когда все объекты относятся к одному классу (энтропия равна нулю), и максимума, когда классы равномерно распределены.

Выигрыш информации (information gain):
Чтобы принять решение о выборе атрибута для разбиения, используется понятие выигрыша информации:

IG(A)=H(S)-∑_(v∈values(A)▒〖|s_v |/|s| *|H(s_v ) 〗
где:
	A — атрибут, по которому осуществляется разбиение,
	Values(A) — возможные значения атрибута,
	Sv — подмножество объектов, соответствующих значению v атрибута A.
Чем больше выигрыш информации, тем предпочтительнее атрибут для текущего шага разбиения.

Также нельзя не вспомнить про критерии по индексу Джинни.
Индекс Джини измеряет долю неправильных классификаций, если случайным образом назначить объекту класс из данного множества. По сути, он показывает вероятность неправильного назначения класса случайным образом. 

I_G (s)=1-∑_(k=1)^k▒p_k^2 
где:
	S — текущее множество данных,
	K — количество классов,
	pk — доля экземпляров класса k в рассматриваемом множестве.
Индекс Джини достигает нуля, когда все объекты в узле принадлежат одному классу, и приближается к единице, когда классы распределяются равномерно.

Выбор критерия зависит от разных факторов, которые рассматриваются уже в процессе решения задачи. К таким факторам можно отнести специфику задачи, объём данных, вычислительные ресурсы. К примеру, если мы хотим построить дерево на маленьком объёме данных, то лучше прибегнуть к использованию критерия Джинни, поскольку тот менее чувствителен к изменениям в распределения классов и быстрее вычисляется.

1.3 Простая нейронная сеть
В конце 1950-ых годов Учёным Фрэнком Розенблатом был разработан перцептрон – по своей сути искусственный нейрон, из которого в последствии будут создаваться нейросети. Перцептрон стал первый действующий обучающийся алгоритм положив начало современному глубокому обучению.
Принцип его работы заключается в том, что на вход перцептрона поступают сигналы (набор признаков x_1,x_2,…,x_n ), которые умножаются на соответствующие им веса (w_1,w_2,…,w_n) и полученные произведения суммируются с добавлением к ним смещения b.

z=w_1 x_1+w_2 x_2+⋯+w_n x_n+b

Затем полученный результат проходит через так называемую функцию активации, которая, в основном, представляет из себя простую ступенчатую функцию такую как:
y={█(1 z>0@0 z≤0)┤

Задача функции активации – добавлять нелинейность в архитектуру нейросети поскольку без неё, модель представляется просто суммированием признаков и настроенных к ним весов. Только благодаря ней нейросети обладают своей особенностью изучать сложные паттерны и зависимости в данных.  Их есть великое множество, к примеру Tanh и sigmoid, они выглядят так:
tanh⁡(x)=(e^x+e^(-x))/(e^x-e^(-x) )

σ(x)=1/(1+e^(-x) )

Tanh переводит входные значения в диапазон от −1 до 1, что способствует лучшему обучению сети, а sigmoid преобразует произвольные вещественные числа в интервал от 0 до 1. Это свойство делает её идеальной для задач бинарной классификации, где выход сети интерпретируется как вероятность принадлежности к одному из классов.
	Веса побираются алгоритмом по мере их важности – чем больше соответствующий признак влияет на результат, тем больше будет его вес. Обычно веса лежать в пределе от 0 до 1. Смещение же, обозначенное переменной b отвечает за изменения положения черты функции в пространстве признаков. Если представить, что у нас есть прямолинейная граница между двумя классами. Без смещения эта линия всегда бы проходила через начало координат, но благодаря b её можно перемещать вверх-вниз или вправо-влево.
Чтобы дальше понимать, как происходит обучение алгоритмов, нужно ввести пару терминов как параметр и гиперпараметр. Параметры – это внутренние характеристики моделей который настраиваются в процессе обучения. В случае нейронных сетей к ним можно отнести вектор весов (w_1,w_1,…,w_n), а также коэффициент смещения b. Гиперпараметры же – это внешние характеристики модели, которые настраиваются, но не изменяются в процессе обучения модели. Обычно они устанавливаются вручную исследователями и требуют предварительной настройки перед обучением. К гиперпараметрам можно отнести количество слоёв в нейросети, глубину дерева решений, размер партии данных, подаваемых на вход.

Процесс обучения нейросети заключается в том, что первым делом на вход мы подаём данные, по которым в последствии настраиваются параметры такие как веса и смещение. Потом мы оцениваем точность по так называемых функциях потерь. В пример можно привести MAE (mean absolute error) и MSE (mean squared error). Они выглядят следующим образом:

MSE=1/N ∑_(i=1)^N▒(y_i-(y_i ) ̅ )^2 

где:
	N — количество примеров в выборке,
	y_i  — истинное значение i-го примера,
	y ̅ — предсказанное значение i-го примера.

MAE=1/N ∑_(i=1)^N▒|y_i-(y_i ) ̅ | 

Всё отличие между двумя формулами заключается в подходе подсчёта ошибки, который выбирается в процессе построения модели. Различия существуют поскольку бывает такое, что встречаются данные, которые мы, к примеру, не можем нормально визуализировать как гладкую функцию не имея квадрата. Гладкая же функция нам нужна чтобы мы смогли занулить функцию потерь с помощью так называемого градиентного спуска. Основная идея градиентного спуска заключается в постепенном движении в направлении уменьшения значения функции потерь, пока не достигнуто локальное или глобальное минимальное значение. Градиентом называют вектор, части которого отражают сторону наибольшего увеличения функции, поэтому используя градиентный спуск мы двигаемся от антиградиента. Предположим, у нас есть функция потерь J(W), где W — вектор параметров нашей модели. Цель — минимизировать J(W).
Шаг градиентного спуска выглядит так:

W_(t+1)=W_t-η∇J(W)
где:
	W^t — текущее значение параметров на шаге t,
	∇J(W) — градиент функции потерь в точке W,
	η — скорость обучения, управляющий размером шагов.
При обучении нейронной сети обычно используются огромные тензоры данных, поэтому зачастую принимается решение строить градиент не по всем данным сразу, а по случайным его частям, так называемым батчам. Этот подход называется стохастическим градиентным спуском (Stochastic Gradient Descent (SGD)).  
Первый проход обучения нейросети называется прямым проходом, а процесс зануления функции потерь и корректировки весов обратным проходом.
Прямой проход:
	На вход подается пакет данных (мини-батч).
	Сигнал распространяется вперед через слои сети активации.
	Выходная активность сверяется с истинными значениями (labels) и вычисляется функция потерь (например, cross entropy или mean squared error).
Обратный проход (backpropagation):
	Используя обратное распространение ошибки, сеть вычисляет градиенты функции потерь по отношению ко всем параметрам.
	Происходит коррекция весов и смещений, направленная на минимизацию функции потерь.

Обратное распространение ошибки — это ключевой алгоритм, позволяющий эффективно вычислять градиенты функции потерь по отношению к параметрам сети. Работает он следующим образом:
	Вычисление градиента функции потерь:
	Сначала находим производную функции потерь по выходу последнего слоя.
	Затем распространяем градиент назад, слой за слоем, пользуясь правилами дифференцирования цепочки.
	Распространение градиентов:
	Для каждого слоя вычисляем частные производные (градиенты) по весам и смещениям.
	Произведения матриц и операций транспонирования используются для эффективных расчетов.
	Корректировка параметров:
	Новые значения параметров получаются путем вычитания пропорциональной доли градиента:

w_jJ^((l) )=w_ⅈj^((l) )-η ∂L/(∂W_jJ^((l) ) )
где:
	W_ij^(l) — вес соединения между нейроном j предыдущего слоя и нейроном i текущего слоя,
	η — скорость обучения,
	∂L/(∂w_ij^l ) — градиент функции потерь по данному весу.
 
 2. Практическая реализация алгоритма для решения задачи
Собственно, в этом разделе приведена практическая реализация алгоритма, а также описание ее работы.
В итоге мы видим, что хорошая разметка данных очень сильно влияет на точность модели поскольку даже максимально простая реализация всех алгоритмов показала высокую точность на отдельных данных

Заключение 
Итак, цель курсовой работы была успешно достигнута. В ходе выполнения работы были решены все поставленные задачи. 
В частности, были и отобраны основные методы к решению задачи классификации такие как стохастический градиентный спуск, деревья решений, случайные леса и нейросети. Были теоретически рассмотрены принципы их работы. Так же был проведен анализ эффективности каждого из методов в ходе которого было выделена эффективность каждого метода.
В ходе практической части был реализован алгоритм классификации вероятности наступления болезни, а именно нейросеть написанная на высокоуровневом фреймворке pytorch, и деревья решений с помощью фреймворка sk-learn. Была проведена предобработка данных, обучение самого алгоритма, а также формирование результатов и оценка качества алгоритма. При чем оценка качества была получена при помощи метрик accuracy, precision, recall и f1-score. Результаты показали высокую точность алгоритмов и его эффективность в решении данной задачи. В итоге нейросеть и классические алгоритмы оказались действительно качественным алгоритмами для решения задач классификации. 
Таким образом имеется готовый продукт для решения задачи классификации. В будущем данный продукт так же будет нести ценность, так как на основе данных, полученных врачами, можно использовать алгоритм для определения диагноза. Полученные знания во время выполнения работы помогут в изучение более сложных архитектур и методов искусственного интеллекта в будущем. 

 
Список использованной литературы
	Онлайн учебник по машинному обучению от ШАД. — Текст: электронный // Яндекс Образование. — URL: https://education.yandex.ru/handbook/ml (дата обращения: 20.03.2025).
	Kaggle: платформа для соревнований по машинному обучению. — Текст: электронный // Kaggle. — URL: https://www.kaggle.com (дата обращения: 20.03.2025).
	Scikit-learn: библиотека машинного обучения для Python. — Текст: электронный // Scikit-learn. — URL: https://scikit-learn.org (дата обращения: 20.03.2025).
	PyTorch: платформа для глубокого обучения. — Текст: электронный // PyTorch. — URL: https://pytorch.org (дата обращения: 20.03.2025).
	OpenML: платформа для обмена наборами данных и экспериментами в области машинного обучения. — Текст: электронный // OpenML. — URL: https://www.openml.org (дата обращения: 20.03.2025).
	Towards Data Science: блог о данных, машинном обучении и искусственном интеллекте. — Текст: электронный // Towards Data Science. — URL: https://towardsdatascience.com (дата обращения: 20.03.2025).
 
